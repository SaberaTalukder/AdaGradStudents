{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'first_neural_network' from '/Users/saberatalukder/Documents/Classes/Winter19-20/CS155/Kaggle/TeamAPlus/first_neural_network.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import importlib\n",
    "import first_neural_network\n",
    "importlib.reload(first_neural_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_0 = 0.1\n",
    "model_0 = nn.Sequential(\n",
    "            nn.Linear(55, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_0),\n",
    "\n",
    "            nn.Linear(200, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_0),\n",
    "\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_0),\n",
    "\n",
    "            nn.Linear(50, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_0),\n",
    "\n",
    "            nn.Linear(10, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "dropout_1 = 0.1\n",
    "model_1 = nn.Sequential(\n",
    "            nn.Linear(55, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_1),\n",
    "\n",
    "            nn.Linear(500, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_1),\n",
    "\n",
    "            nn.Linear(50, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "dropout_2 = 0.2\n",
    "model_2 = nn.Sequential(\n",
    "            nn.Linear(55, 500),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_2),\n",
    "\n",
    "            nn.Linear(500, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_2),\n",
    "\n",
    "            nn.Linear(1000, 400),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_2),\n",
    "\n",
    "            nn.Linear(400, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_2),\n",
    "\n",
    "            nn.Linear(50, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "dropout_3 = 0.15\n",
    "model_3 = nn.Sequential(\n",
    "            nn.Linear(55, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_3),\n",
    "\n",
    "            nn.Linear(200, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_3),\n",
    "\n",
    "            nn.Linear(100, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "dropout_4 = 0.15\n",
    "model_4 = nn.Sequential(\n",
    "            nn.Linear(55, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_4),\n",
    "\n",
    "            nn.Linear(200, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_4),\n",
    "\n",
    "            nn.Linear(100, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_4),\n",
    "\n",
    "            nn.Linear(50, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_4),\n",
    "\n",
    "            nn.Linear(10, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "model_list = [model_0, model_1, model_2, model_3, model_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_no_nan = pd.read_pickle('george_process_1_then_sharon_nan_drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(592380, 58)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_no_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592380\n",
      "Fold  1  of  3  test indices: [     0      1      2 ... 197457 197458 197459]\n",
      "len(val_index_list):  197460\n",
      "x train tensor:  tensor([[-2.1965e+00, -2.1984e+00, -5.6417e-01,  ...,  4.0740e-01,\n",
      "          1.2629e-01,  4.7410e-01],\n",
      "        [-2.1965e+00, -2.1965e+00, -7.9252e-02,  ..., -8.3991e-01,\n",
      "          5.4457e-01, -3.0243e-03],\n",
      "        [-2.1928e+00, -2.1947e+00, -7.9252e-02,  ..., -3.5485e-01,\n",
      "         -2.9903e-01,  4.7407e-01],\n",
      "        ...,\n",
      "        [ 1.7876e+00,  1.8080e+00, -5.6417e-01,  ..., -1.6828e-01,\n",
      "         -9.0391e-03, -4.9756e+00],\n",
      "        [ 1.7876e+00,  1.8080e+00, -5.6417e-01,  ..., -1.6828e-01,\n",
      "         -9.0391e-03, -4.9756e+00],\n",
      "        [ 1.7876e+00,  1.8080e+00, -5.6417e-01,  ..., -1.6828e-01,\n",
      "         -9.0391e-03, -4.9756e+00]])\n",
      "y train tensor:  tensor([[1.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Train Epoch: 1  Loss: 0.6874\n",
      "Train Epoch: 2  Loss: 0.5903\n",
      "Train Epoch: 3  Loss: 0.4304\n",
      "Train Epoch: 4  Loss: 0.6728\n",
      "Train Epoch: 5  Loss: 0.6265\n",
      "Train Epoch: 6  Loss: 0.6109\n",
      "Train Epoch: 7  Loss: 0.7923\n",
      "Train Epoch: 8  Loss: 0.5331\n",
      "Train Epoch: 9  Loss: 0.8616\n",
      "Train Epoch: 10  Loss: 0.4940\n",
      "validation error:  0.6665549235058323\n",
      "Fold  2  of  3  test indices: [197460 197461 197462 ... 394917 394918 394919]\n",
      "len(val_index_list):  197460\n",
      "x train tensor:  tensor([[-1.2484, -1.2462,  4.7181,  ...,  0.3060,  0.9749, -0.9766],\n",
      "        [-1.2439, -1.2372,  2.3134,  ..., -0.0403, -0.7917, -2.9334],\n",
      "        [-1.2304, -1.2270,  2.7944,  ...,  1.3729,  0.2484, -1.4653],\n",
      "        ...,\n",
      "        [ 1.7568,  1.7692, -0.5722,  ..., -0.2002, -0.0422, -5.0300],\n",
      "        [ 1.7568,  1.7692, -0.5722,  ..., -0.2002, -0.0422, -5.0300],\n",
      "        [ 1.7568,  1.7692, -0.5722,  ..., -0.2002, -0.0422, -5.0300]])\n",
      "y train tensor:  tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "Train Epoch: 1  Loss: 0.5617\n",
      "Train Epoch: 2  Loss: 0.7076\n",
      "Train Epoch: 3  Loss: 0.8913\n",
      "Train Epoch: 4  Loss: 0.7341\n",
      "Train Epoch: 5  Loss: 0.4653\n",
      "Train Epoch: 6  Loss: 0.6139\n",
      "Train Epoch: 7  Loss: 0.5696\n",
      "Train Epoch: 8  Loss: 0.3676\n",
      "Train Epoch: 9  Loss: 0.7356\n",
      "Train Epoch: 10  Loss: 0.7454\n",
      "validation error:  0.676183199662813\n",
      "Fold  3  of  3  test indices: [394920 394921 394922 ... 592377 592378 592379]\n",
      "len(val_index_list):  197460\n",
      "x train tensor:  tensor([[-1.1733, -1.1707,  5.0721,  ...,  0.3101,  0.9776, -0.9769],\n",
      "        [-1.1680, -1.1600,  2.5137,  ..., -0.0372, -0.7878, -2.9193],\n",
      "        [-1.1521, -1.1481,  3.0254,  ...,  1.3797,  0.2516, -1.4620],\n",
      "        ...,\n",
      "        [ 1.5198,  1.5252, -0.0446,  ..., -0.0372, -0.4454, -1.8511],\n",
      "        [ 1.5198,  1.5225, -0.5563,  ..., -0.0372,  0.6388, -0.9283],\n",
      "        [ 1.5172,  1.5199, -0.5563,  ...,  0.6574,  0.8324, -0.9283]])\n",
      "y train tensor:  tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.]])\n",
      "Train Epoch: 1  Loss: 0.6326\n",
      "Train Epoch: 2  Loss: 0.5902\n",
      "Train Epoch: 3  Loss: 0.6401\n",
      "Train Epoch: 4  Loss: 0.5492\n"
     ]
    }
   ],
   "source": [
    "import get_average_val_err\n",
    "\n",
    "for idx, m in enumerate(model_list):\n",
    "    model = first_neural_network.first_neural_network(model = m)\n",
    "    importlib.reload(get_average_val_err)\n",
    "    val,var,all_val = get_average_val_err.get_val_err(3, train_no_nan, model)\n",
    "    print('idx: ', idx)\n",
    "    print('val: ', val)\n",
    "    model.fit(train_no_nan.drop(['id','date','y'], axis=1), train_no_nan[[\"y\"]])\n",
    "    test[\"Predicted\"] = model.predict(test_no_nan.drop([\"id\",\"date\",\"y\"],axis=1))\n",
    "    test[[\"id\",\"Predicted\"]].to_csv(f\"sabera_submission_epochs_more_layers_test_multi_{idx}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
